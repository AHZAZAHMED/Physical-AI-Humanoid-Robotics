"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[173],{5035:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>t,contentTitle:()=>l,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"module-2/sensor-simulation","title":"Sensor Simulation","description":"Sensor simulation is critical for robotics development, allowing for testing and training without physical hardware. This module covers simulating various sensors used in humanoid robotics, including LiDAR, cameras, IMUs, and force/torque sensors.","source":"@site/docs/module-2/sensor-simulation.md","sourceDirName":"module-2","slug":"/module-2/sensor-simulation","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-2/sensor-simulation","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1765393240000,"frontMatter":{"title":"Sensor Simulation"},"sidebar":"tutorialSidebar","previous":{"title":"Unity and High-Fidelity Rendering","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-2/unity-and-high-fidelity-rendering"},"next":{"title":"Isaac Sim and SDK","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-3/isaac-sim-and-sdk"}}');var a=i(4848),r=i(8453);const o={title:"Sensor Simulation"},l="Sensor Simulation",t={},d=[{value:"Overview of Sensor Simulation",id:"overview-of-sensor-simulation",level:2},{value:"Camera Simulation",id:"camera-simulation",level:2},{value:"Pinhole Camera Model",id:"pinhole-camera-model",level:3},{value:"Camera Parameters in URDF/SDF",id:"camera-parameters-in-urdfsdf",level:3},{value:"Camera Calibration",id:"camera-calibration",level:3},{value:"LiDAR Simulation",id:"lidar-simulation",level:2},{value:"Ray-based Simulation",id:"ray-based-simulation",level:3},{value:"LiDAR Configuration in Gazebo",id:"lidar-configuration-in-gazebo",level:3},{value:"Types of LiDAR Simulation",id:"types-of-lidar-simulation",level:3},{value:"IMU Simulation",id:"imu-simulation",level:2},{value:"IMU Components",id:"imu-components",level:3},{value:"IMU Simulation in Gazebo",id:"imu-simulation-in-gazebo",level:3},{value:"Force/Torque Sensor Simulation",id:"forcetorque-sensor-simulation",level:2},{value:"Sensor Fusion in Simulation",id:"sensor-fusion-in-simulation",level:2},{value:"Combining Multiple Sensors",id:"combining-multiple-sensors",level:3},{value:"Multi-Sensor Integration",id:"multi-sensor-integration",level:3},{value:"Realism Considerations",id:"realism-considerations",level:2},{value:"Noise Modeling",id:"noise-modeling",level:3},{value:"Environmental Effects",id:"environmental-effects",level:3},{value:"Validation and Verification",id:"validation-and-verification",level:2},{value:"Ground Truth Comparison",id:"ground-truth-comparison",level:3},{value:"Sensor-Specific Validation",id:"sensor-specific-validation",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"sensor-simulation",children:"Sensor Simulation"})}),"\n",(0,a.jsx)(e.p,{children:"Sensor simulation is critical for robotics development, allowing for testing and training without physical hardware. This module covers simulating various sensors used in humanoid robotics, including LiDAR, cameras, IMUs, and force/torque sensors."}),"\n",(0,a.jsx)(e.h2,{id:"overview-of-sensor-simulation",children:"Overview of Sensor Simulation"}),"\n",(0,a.jsx)(e.p,{children:"Sensor simulation in robotics environments like Gazebo and Unity allows:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Algorithm Development"}),": Test perception and control algorithms"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Data Generation"}),": Create labeled datasets for training"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Safety Testing"}),": Evaluate robot behavior in dangerous scenarios"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Cost Reduction"}),": Reduce reliance on expensive hardware"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Repeatability"}),": Exact reproduction of test scenarios"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"camera-simulation",children:"Camera Simulation"}),"\n",(0,a.jsx)(e.h3,{id:"pinhole-camera-model",children:"Pinhole Camera Model"}),"\n",(0,a.jsx)(e.p,{children:"The pinhole camera model is the foundation for most camera simulations:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{children:"u = fx * (X/Z) + cx\nv = fy * (Y/Z) + cy\n"})}),"\n",(0,a.jsx)(e.p,{children:"Where:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"(u, v) are pixel coordinates"}),"\n",(0,a.jsx)(e.li,{children:"(X, Y, Z) are 3D world coordinates"}),"\n",(0,a.jsx)(e.li,{children:"fx, fy are focal lengths"}),"\n",(0,a.jsx)(e.li,{children:"cx, cy are principal point offsets"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"camera-parameters-in-urdfsdf",children:"Camera Parameters in URDF/SDF"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<gazebo reference="camera_link">\n  <sensor type="camera" name="camera1">\n    <update_rate>30.0</update_rate>\n    <camera name="head">\n      <horizontal_fov>1.3962634</horizontal_fov>\n      <image>\n        <width>800</width>\n        <height>800</height>\n        <format>R8G8B8</format>\n      </image>\n      <clip>\n        <near>0.1</near>\n        <far>100</far>\n      </clip>\n      <noise>\n        <type>gaussian</type>\n        <mean>0.0</mean>\n        <stddev>0.007</stddev>\n      </noise>\n    </camera>\n    <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n      <frame_name>camera_optical_frame</frame_name>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"camera-calibration",children:"Camera Calibration"}),"\n",(0,a.jsx)(e.p,{children:"Simulated cameras should match real camera parameters:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Intrinsic Parameters"}),": Focal length, principal point, distortion"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Extrinsic Parameters"}),": Position and orientation relative to robot"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Distortion Models"}),": Radial and tangential distortion coefficients"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"lidar-simulation",children:"LiDAR Simulation"}),"\n",(0,a.jsx)(e.h3,{id:"ray-based-simulation",children:"Ray-based Simulation"}),"\n",(0,a.jsx)(e.p,{children:"LiDAR sensors are simulated using ray tracing:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Rays are cast from the sensor origin"}),"\n",(0,a.jsx)(e.li,{children:"Distance to nearest obstacle is recorded"}),"\n",(0,a.jsx)(e.li,{children:"Multiple rays form a scan pattern"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"lidar-configuration-in-gazebo",children:"LiDAR Configuration in Gazebo"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<gazebo reference="lidar_link">\n  <sensor type="ray" name="lidar_sensor">\n    <ray>\n      <scan>\n        <horizontal>\n          <samples>720</samples>\n          <resolution>1</resolution>\n          <min_angle>-3.14159</min_angle>\n          <max_angle>3.14159</max_angle>\n        </horizontal>\n      </scan>\n      <range>\n        <min>0.10</min>\n        <max>30.0</max>\n        <resolution>0.01</resolution>\n      </range>\n    </ray>\n    <plugin name="lidar_plugin" filename="libgazebo_ros_ray_sensor.so">\n      <ros>\n        <namespace>/lidar</namespace>\n        <remapping>~/out:=scan</remapping>\n      </ros>\n      <output_type>sensor_msgs/LaserScan</output_type>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,a.jsx)(e.h3,{id:"types-of-lidar-simulation",children:"Types of LiDAR Simulation"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"2D LiDAR"}),": Single horizontal plane"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"3D LiDAR"}),": Multiple planes (Velodyne-style)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Solid Angle"}),": Conical or custom scan patterns"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"imu-simulation",children:"IMU Simulation"}),"\n",(0,a.jsx)(e.h3,{id:"imu-components",children:"IMU Components"}),"\n",(0,a.jsx)(e.p,{children:"An IMU typically provides:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Accelerometer"}),": Linear acceleration in 3 axes"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Gyroscope"}),": Angular velocity in 3 axes"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Magnetometer"}),": Magnetic field (compass heading)"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"imu-simulation-in-gazebo",children:"IMU Simulation in Gazebo"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<gazebo reference="imu_link">\n  <sensor name="imu_sensor" type="imu">\n    <always_on>true</always_on>\n    <update_rate>100</update_rate>\n    <visualize>true</visualize>\n    <imu>\n      <angular_velocity>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n            <bias_mean>0.0000075</bias_mean>\n            <bias_stddev>0.0000008</bias_stddev>\n          </noise>\n        </z>\n      </angular_velocity>\n      <linear_acceleration>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n            <bias_mean>0.1</bias_mean>\n            <bias_stddev>0.001</bias_stddev>\n          </noise>\n        </z>\n      </linear_acceleration>\n    </imu>\n    <plugin name="imu_plugin" filename="libgazebo_ros_imu.so">\n      <ros>\n        <namespace>/imu</namespace>\n        <remapping>~/out:=imu/data</remapping>\n      </ros>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"forcetorque-sensor-simulation",children:"Force/Torque Sensor Simulation"}),"\n",(0,a.jsx)(e.p,{children:"Force/torque sensors measure forces and torques applied to a robot joint or link:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-xml",children:'<gazebo>\n  <joint name="force_torque_joint" type="fixed">\n    <parent>parent_link</parent>\n    <child>sensor_link</child>\n  </joint>\n\n  <sensor name="force_torque_sensor" type="force_torque">\n    <always_on>true</always_on>\n    <update_rate>100</update_rate>\n    <force_torque>\n      <frame>sensor_local</frame>\n      <measure_direction>child_to_parent</measure_direction>\n    </force_torque>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,a.jsx)(e.h2,{id:"sensor-fusion-in-simulation",children:"Sensor Fusion in Simulation"}),"\n",(0,a.jsx)(e.h3,{id:"combining-multiple-sensors",children:"Combining Multiple Sensors"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Kalman Filters"}),": Combine sensor readings optimally"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Particle Filters"}),": Handle non-linear sensor models"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Complementary Filters"}),": Combine sensors with different characteristics"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"multi-sensor-integration",children:"Multi-Sensor Integration"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Temporal Synchronization"}),": Align sensor timestamps"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Spatial Calibration"}),": Transform between sensor frames"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Covariance Estimation"}),": Model sensor uncertainties"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"realism-considerations",children:"Realism Considerations"}),"\n",(0,a.jsx)(e.h3,{id:"noise-modeling",children:"Noise Modeling"}),"\n",(0,a.jsx)(e.p,{children:"Real sensors have various types of noise:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Gaussian Noise"}),": Random measurement errors"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Bias"}),": Systematic measurement offsets"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Drift"}),": Slow changes in bias over time"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Quantization"}),": Discrete measurement steps"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"environmental-effects",children:"Environmental Effects"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Weather"}),": Rain, fog, snow affecting sensors"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Lighting"}),": Changes in illumination"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Occlusions"}),": Objects blocking sensor view"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Reflections"}),": Unexpected sensor returns"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"validation-and-verification",children:"Validation and Verification"}),"\n",(0,a.jsx)(e.h3,{id:"ground-truth-comparison",children:"Ground Truth Comparison"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Known Environments"}),": Compare sensor output to actual values"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Synthetic Data"}),": Use known ground truth for perception training"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Domain Adaptation"}),": Bridge simulation-to-reality gap"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"sensor-specific-validation",children:"Sensor-Specific Validation"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Camera"}),": Check calibration parameters and distortion"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"LiDAR"}),": Validate range accuracy and resolution"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"IMU"}),": Verify noise characteristics and bias"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Encoders"}),": Confirm resolution and accuracy"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Parameter Matching"}),": Match simulated sensor parameters to real hardware"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Noise Modeling"}),": Include realistic noise models"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Validation"}),": Regularly validate simulation against real sensors"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Performance"}),": Balance sensor fidelity with simulation speed"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Documentation"}),": Maintain clear specifications for each sensor model"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"After completing this module, you will be able to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Configure camera, LiDAR, IMU, and other sensor simulations"}),"\n",(0,a.jsx)(e.li,{children:"Apply appropriate noise models to simulated sensors"}),"\n",(0,a.jsx)(e.li,{children:"Validate simulated sensors against real hardware"}),"\n",(0,a.jsx)(e.li,{children:"Implement sensor fusion techniques in simulation"}),"\n",(0,a.jsx)(e.li,{children:"Consider environmental effects on sensor performance"}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(c,{...n})}):c(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>l});var s=i(6540);const a={},r=s.createContext(a);function o(n){const e=s.useContext(r);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),s.createElement(r.Provider,{value:e},n.children)}}}]);