"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[767],{6989:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>m,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module-4/humanoid-kinematics-and-control","title":"Humanoid Kinematics and Control","description":"Humanoid kinematics and control form the foundation for enabling human-like movement and interaction in robotic systems. This module covers the mathematical foundations, control strategies, and implementation techniques for humanoid robot motion.","source":"@site/docs/module-4/humanoid-kinematics-and-control.md","sourceDirName":"module-4","slug":"/module-4/humanoid-kinematics-and-control","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-4/humanoid-kinematics-and-control","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1765393240000,"frontMatter":{"title":"Humanoid Kinematics and Control"},"sidebar":"tutorialSidebar","previous":{"title":"Cognitive Planning","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-4/cognitive-planning"},"next":{"title":"Hardware Requirements","permalink":"/Physical-AI-Humanoid-Robotics/docs/assessments/hardware-requirements"}}');var i=t(4848),r=t(8453);const a={title:"Humanoid Kinematics and Control"},s="Humanoid Kinematics and Control",l={},c=[{value:"Introduction to Humanoid Kinematics",id:"introduction-to-humanoid-kinematics",level:2},{value:"Humanoid Robot Kinematic Structure",id:"humanoid-robot-kinematic-structure",level:2},{value:"Degrees of Freedom",id:"degrees-of-freedom",level:3},{value:"Common Configurations",id:"common-configurations",level:3},{value:"Forward Kinematics",id:"forward-kinematics",level:2},{value:"Mathematical Representation",id:"mathematical-representation",level:3},{value:"Using Modern Libraries",id:"using-modern-libraries",level:3},{value:"Inverse Kinematics",id:"inverse-kinematics",level:2},{value:"Analytical vs Numerical Solutions",id:"analytical-vs-numerical-solutions",level:3},{value:"Numerical IK Implementation",id:"numerical-ik-implementation",level:3},{value:"Jacobian-based IK",id:"jacobian-based-ik",level:3},{value:"Balance and Stability Control",id:"balance-and-stability-control",level:2},{value:"Zero Moment Point (ZMP)",id:"zero-moment-point-zmp",level:3},{value:"Capture Point",id:"capture-point",level:3},{value:"Walking Pattern Generation",id:"walking-pattern-generation",level:2},{value:"Inverted Pendulum Model",id:"inverted-pendulum-model",level:3},{value:"Whole-Body Control",id:"whole-body-control",level:2},{value:"Task-Priority Framework",id:"task-priority-framework",level:3},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"Joint Trajectory Control",id:"joint-trajectory-control",level:3},{value:"Walking Control Implementation",id:"walking-control-implementation",level:2},{value:"Walking State Machine",id:"walking-state-machine",level:3},{value:"Balance Recovery Strategies",id:"balance-recovery-strategies",level:2},{value:"Push Recovery",id:"push-recovery",level:3},{value:"Simulation and Validation",id:"simulation-and-validation",level:2},{value:"Gazebo Integration",id:"gazebo-integration",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Real-time Requirements",id:"real-time-requirements",level:3},{value:"Optimization Techniques",id:"optimization-techniques",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"humanoid-kinematics-and-control",children:"Humanoid Kinematics and Control"})}),"\n",(0,i.jsx)(e.p,{children:"Humanoid kinematics and control form the foundation for enabling human-like movement and interaction in robotic systems. This module covers the mathematical foundations, control strategies, and implementation techniques for humanoid robot motion."}),"\n",(0,i.jsx)(e.h2,{id:"introduction-to-humanoid-kinematics",children:"Introduction to Humanoid Kinematics"}),"\n",(0,i.jsx)(e.p,{children:"Humanoid kinematics involves:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Forward Kinematics"}),": Computing end-effector positions from joint angles"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Inverse Kinematics"}),": Computing joint angles from desired end-effector positions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Jacobian Computation"}),": Relating joint velocities to end-effector velocities"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Dynamics"}),": Understanding forces and torques in motion"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Balance Control"}),": Maintaining stability during movement"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"humanoid-robot-kinematic-structure",children:"Humanoid Robot Kinematic Structure"}),"\n",(0,i.jsx)(e.h3,{id:"degrees-of-freedom",children:"Degrees of Freedom"}),"\n",(0,i.jsx)(e.p,{children:"Humanoid robots typically have:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Legs"}),": 6+ DOF each (hip, knee, ankle)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Arms"}),": 7+ DOF each (shoulder, elbow, wrist)"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Torso"}),": 2-3 DOF for upper body movement"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Head"}),": 2-3 DOF for gaze control"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Total"}),": 30+ DOF for full humanoid"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"common-configurations",children:"Common Configurations"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"NAO"}),": 25 DOF, small humanoid"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Pepper"}),": 20 DOF, social robot"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"ATLAS"}),": 28+ DOF, large humanoid"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Honda ASIMO"}),": 57 DOF, advanced humanoid"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"forward-kinematics",children:"Forward Kinematics"}),"\n",(0,i.jsx)(e.h3,{id:"mathematical-representation",children:"Mathematical Representation"}),"\n",(0,i.jsx)(e.p,{children:"Forward kinematics computes the position and orientation of end-effectors given joint angles:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom scipy.spatial.transform import Rotation as R\n\ndef dh_transform(a, alpha, d, theta):\n    """\n    Denavit-Hartenberg transformation matrix\n    """\n    ct = np.cos(theta)\n    st = np.sin(theta)\n    ca = np.cos(alpha)\n    sa = np.sin(alpha)\n\n    T = np.array([\n        [ct, -st*ca, st*sa, a*ct],\n        [st, ct*ca, -ct*sa, a*st],\n        [0, sa, ca, d],\n        [0, 0, 0, 1]\n    ])\n    return T\n\ndef forward_kinematics(joint_angles, dh_params):\n    """\n    Compute forward kinematics for a robot chain\n    """\n    T_total = np.eye(4)\n\n    for i, (a, alpha, d, theta_offset) in enumerate(dh_params):\n        theta = theta_offset + joint_angles[i]\n        T_link = dh_transform(a, alpha, d, theta)\n        T_total = T_total @ T_link\n\n    return T_total\n'})}),"\n",(0,i.jsx)(e.h3,{id:"using-modern-libraries",children:"Using Modern Libraries"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import roboticstoolbox as rtb\nimport spatialmath as sm\n\n# Create a robot model\nrobot = rtb.DHRobot([\n    rtb.RevoluteDH(a=0.1, alpha=np.pi/2, d=0.2, offset=0),\n    rtb.RevoluteDH(a=0.2, alpha=0, d=0, offset=0),\n    # Add more links as needed\n])\n\n# Compute forward kinematics\nq = [0.1, 0.2, 0.3]  # Joint angles\nT = robot.fkine(q)  # Forward kinematics\nprint(f"End-effector pose: {T}")\n'})}),"\n",(0,i.jsx)(e.h2,{id:"inverse-kinematics",children:"Inverse Kinematics"}),"\n",(0,i.jsx)(e.h3,{id:"analytical-vs-numerical-solutions",children:"Analytical vs Numerical Solutions"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Analytical"}),": Exact solutions for simple kinematic chains"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Numerical"}),": Iterative solutions for complex robots"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"numerical-ik-implementation",children:"Numerical IK Implementation"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import numpy as np\nfrom scipy.optimize import minimize\n\ndef inverse_kinematics_numerical(robot, target_pose, q_init):\n    """\n    Solve inverse kinematics using numerical optimization\n    """\n    def objective(q):\n        # Compute current pose\n        current_pose = robot.fkine(q)\n\n        # Calculate error\n        pos_error = np.linalg.norm(target_pose.t - current_pose.t)\n        rot_error = np.arccos(\n            np.clip((np.trace(target_pose.R.T @ current_pose.R) - 1) / 2, -1, 1)\n        )\n\n        return pos_error + 0.1 * rot_error\n\n    result = minimize(objective, q_init, method=\'BFGS\')\n\n    if result.success:\n        return result.x\n    else:\n        raise ValueError("IK solution not found")\n'})}),"\n",(0,i.jsx)(e.h3,{id:"jacobian-based-ik",children:"Jacobian-based IK"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'def jacobian_ik(robot, target_pose, q_init, max_iterations=100, tolerance=1e-4):\n    """\n    Solve IK using Jacobian transpose/pseudoinverse method\n    """\n    q = q_init.copy()\n\n    for i in range(max_iterations):\n        current_pose = robot.fkine(q)\n\n        # Calculate error\n        pos_error = target_pose.t - current_pose.t\n        rot_error = (target_pose.R - current_pose.R).ravel()\n\n        error = np.concatenate([pos_error, rot_error])\n\n        if np.linalg.norm(error) < tolerance:\n            break\n\n        # Compute Jacobian\n        J = robot.jacob0(q)\n\n        # Update joint angles\n        dq = np.linalg.pinv(J) @ error\n        q = q + 0.1 * dq  # Learning rate\n\n    return q\n'})}),"\n",(0,i.jsx)(e.h2,{id:"balance-and-stability-control",children:"Balance and Stability Control"}),"\n",(0,i.jsx)(e.h3,{id:"zero-moment-point-zmp",children:"Zero Moment Point (ZMP)"}),"\n",(0,i.jsx)(e.p,{children:"The ZMP is crucial for bipedal stability:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class BalanceController:\n    def __init__(self, robot_mass, gravity=9.81):\n        self.mass = robot_mass\n        self.gravity = gravity\n        self.kp = 10.0  # Proportional gain\n        self.kd = 2.0   # Derivative gain\n\n    def compute_zmp(self, com_pos, com_vel, com_acc):\n        """\n        Compute Zero Moment Point\n        """\n        zmp_x = com_pos[0] - (com_acc[0] * com_pos[2]) / self.gravity\n        zmp_y = com_pos[1] - (com_acc[1] * com_pos[2]) / self.gravity\n\n        return np.array([zmp_x, zmp_y, 0.0])\n\n    def balance_control(self, desired_zmp, current_zmp, current_com, dt):\n        """\n        Balance control using ZMP feedback\n        """\n        zmp_error = desired_zmp[:2] - current_zmp[:2]\n\n        # Compute desired COM acceleration\n        com_acc_desired = self.gravity / current_com[2] * zmp_error\n\n        return com_acc_desired\n'})}),"\n",(0,i.jsx)(e.h3,{id:"capture-point",children:"Capture Point"}),"\n",(0,i.jsx)(e.p,{children:"The capture point indicates where to step to stop:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'def compute_capture_point(com_pos, com_vel, com_height):\n    """\n    Compute capture point for balance recovery\n    """\n    omega = np.sqrt(9.81 / com_height)\n    capture_x = com_pos[0] + com_vel[0] / omega\n    capture_y = com_pos[1] + com_vel[1] / omega\n\n    return np.array([capture_x, capture_y])\n'})}),"\n",(0,i.jsx)(e.h2,{id:"walking-pattern-generation",children:"Walking Pattern Generation"}),"\n",(0,i.jsx)(e.h3,{id:"inverted-pendulum-model",children:"Inverted Pendulum Model"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class WalkingPatternGenerator:\n    def __init__(self, step_height=0.05, step_length=0.3, step_time=1.0):\n        self.step_height = step_height\n        self.step_length = step_length\n        self.step_time = step_time\n\n    def generate_foot_trajectory(self, start_pos, goal_pos, t):\n        """\n        Generate smooth foot trajectory\n        """\n        # Linear interpolation for horizontal movement\n        x = start_pos[0] + (goal_pos[0] - start_pos[0]) * t\n        y = start_pos[1] + (goal_pos[1] - start_pos[1]) * t\n\n        # Vertical movement (parabolic lift)\n        if t < 0.5:\n            z = self.step_height * 4 * t  # Lift up\n        else:\n            z = self.step_height * 4 * (1 - t)  # Lift down\n\n        return np.array([x, y, z])\n\n    def generate_com_trajectory(self, support_foot, swing_foot, t):\n        """\n        Generate Center of Mass trajectory following the inverted pendulum\n        """\n        # Simplified: CoM follows a smooth path between feet\n        com_x = support_foot[0] + (swing_foot[0] - support_foot[0]) * t * 0.5\n        com_y = support_foot[1] + (swing_foot[1] - support_foot[1]) * t * 0.5\n\n        # Maintain constant height for stability\n        com_z = 0.8  # Typical CoM height for humanoid\n\n        return np.array([com_x, com_y, com_z])\n'})}),"\n",(0,i.jsx)(e.h2,{id:"whole-body-control",children:"Whole-Body Control"}),"\n",(0,i.jsx)(e.h3,{id:"task-priority-framework",children:"Task-Priority Framework"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:"class WholeBodyController:\n    def __init__(self, robot):\n        self.robot = robot\n        self.tasks = []\n\n    def add_task(self, task_name, jacobian, desired_velocity, priority=0):\n        \"\"\"\n        Add a control task with priority\n        \"\"\"\n        task = {\n            'name': task_name,\n            'J': jacobian,\n            'v_des': desired_velocity,\n            'priority': priority\n        }\n        self.tasks.append(task)\n\n        # Sort tasks by priority (higher priority first)\n        self.tasks.sort(key=lambda x: x['priority'], reverse=True)\n\n    def compute_joint_velocities(self):\n        \"\"\"\n        Compute joint velocities using task-priority framework\n        \"\"\"\n        q_dot = np.zeros(self.robot.n)\n        I = np.eye(self.robot.n)\n\n        for task in self.tasks:\n            J = task['J']\n            v_des = task['v_des']\n\n            # Compute null space projection\n            J_pinv = np.linalg.pinv(J @ I)\n            q_dot_task = J_pinv @ (v_des - J @ q_dot)\n\n            # Update joint velocities\n            q_dot = q_dot + q_dot_task\n\n            # Update null space projector\n            I = I - J_pinv @ J\n\n        return q_dot\n"})}),"\n",(0,i.jsx)(e.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,i.jsx)(e.h3,{id:"joint-trajectory-control",children:"Joint Trajectory Control"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'import rclpy\nfrom rclpy.node import Node\nfrom trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint\nfrom builtin_interfaces.msg import Duration\n\nclass HumanoidController(Node):\n    def __init__(self):\n        super().__init__(\'humanoid_controller\')\n\n        # Joint trajectory publisher\n        self.joint_pub = self.create_publisher(\n            JointTrajectory,\n            \'/joint_trajectory\',\n            10\n        )\n\n        # Initialize kinematics\n        self.kinematics = self.initialize_kinematics()\n\n    def send_trajectory(self, joint_names, positions, times):\n        """\n        Send joint trajectory to robot\n        """\n        traj_msg = JointTrajectory()\n        traj_msg.joint_names = joint_names\n\n        for pos, time in zip(positions, times):\n            point = JointTrajectoryPoint()\n            point.positions = pos\n            point.time_from_start = Duration(sec=int(time), nanosec=int((time % 1) * 1e9))\n            traj_msg.points.append(point)\n\n        self.joint_pub.publish(traj_msg)\n\n    def move_to_pose(self, target_pose, end_effector_name):\n        """\n        Move end effector to target pose using IK\n        """\n        # Solve inverse kinematics\n        joint_angles = self.inverse_kinematics(target_pose, end_effector_name)\n\n        # Send to robot\n        joint_names = self.get_joint_names(end_effector_name)\n        self.send_trajectory([joint_names], [joint_angles], [2.0])  # 2 second move\n'})}),"\n",(0,i.jsx)(e.h2,{id:"walking-control-implementation",children:"Walking Control Implementation"}),"\n",(0,i.jsx)(e.h3,{id:"walking-state-machine",children:"Walking State Machine"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'from enum import Enum\n\nclass WalkingState(Enum):\n    STANDING = 1\n    LEFT_SWING = 2\n    RIGHT_SWING = 3\n    DOUBLE_SUPPORT = 4\n\nclass WalkingController:\n    def __init__(self):\n        self.state = WalkingState.STANDING\n        self.left_foot_support = True\n        self.cycle_time = 1.0\n        self.current_time = 0.0\n        self.step_count = 0\n\n    def update(self, dt):\n        """\n        Update walking state machine\n        """\n        self.current_time += dt\n\n        if self.current_time >= self.cycle_time:\n            self.current_time = 0.0\n            self.toggle_support_foot()\n            self.step_count += 1\n\n        # Generate appropriate trajectories based on state\n        left_foot_pos = self.generate_foot_trajectory(\'left\', self.current_time / self.cycle_time)\n        right_foot_pos = self.generate_foot_trajectory(\'right\', self.current_time / self.cycle_time)\n\n        return left_foot_pos, right_foot_pos\n\n    def generate_foot_trajectory(self, foot, phase):\n        """\n        Generate foot trajectory based on walking phase\n        """\n        if foot == \'left\' and self.left_foot_support:\n            # Left foot is support foot - stay in place\n            return self.get_support_foot_position()\n        elif foot == \'right\' and not self.left_foot_support:\n            # Right foot is support foot - stay in place\n            return self.get_support_foot_position()\n        else:\n            # Swing foot trajectory\n            return self.get_swing_foot_trajectory(phase)\n\n    def toggle_support_foot(self):\n        """\n        Toggle which foot is the support foot\n        """\n        self.left_foot_support = not self.left_foot_support\n'})}),"\n",(0,i.jsx)(e.h2,{id:"balance-recovery-strategies",children:"Balance Recovery Strategies"}),"\n",(0,i.jsx)(e.h3,{id:"push-recovery",children:"Push Recovery"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'class BalanceRecovery:\n    def __init__(self, robot_controller):\n        self.controller = robot_controller\n        self.critical_angle = np.radians(15)  # 15 degrees\n\n    def detect_imminent_fall(self, imu_data, com_state):\n        """\n        Detect if robot is about to fall\n        """\n        roll, pitch = imu_data[\'orientation\'][:2]\n\n        if abs(roll) > self.critical_angle or abs(pitch) > self.critical_angle:\n            return True\n\n        # Check if CoM is outside support polygon\n        if self.is_com_outside_support(com_state):\n            return True\n\n        return False\n\n    def execute_recovery(self, recovery_strategy=\'step\'):\n        """\n        Execute balance recovery based on strategy\n        """\n        if recovery_strategy == \'step\':\n            self.take_recovery_step()\n        elif recovery_strategy == \'crouch\':\n            self.crouch_down()\n        elif recovery_strategy == \'arm_swing\':\n            self.swing_arms_for_balance()\n\n    def take_recovery_step(self):\n        """\n        Take a step to recover balance\n        """\n        # Compute capture point\n        capture_point = self.compute_capture_point()\n\n        # Take step toward capture point\n        self.controller.step_to(capture_point)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"simulation-and-validation",children:"Simulation and Validation"}),"\n",(0,i.jsx)(e.h3,{id:"gazebo-integration",children:"Gazebo Integration"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-xml",children:'\x3c!-- Humanoid robot control plugin --\x3e\n<gazebo>\n  <plugin name="humanoid_control_plugin" filename="libhumanoid_control.so">\n    <robot_namespace>/humanoid</robot_namespace>\n    <joints>\n      <joint>left_hip_roll</joint>\n      <joint>left_hip_yaw</joint>\n      <joint>left_hip_pitch</joint>\n      <joint>left_knee</joint>\n      <joint>left_ankle_pitch</joint>\n      <joint>left_ankle_roll</joint>\n      \x3c!-- Add all other joints --\x3e\n    </joints>\n    <control_mode>position</control_mode>\n    <gains>\n      <left_hip_roll_p>100.0</left_hip_roll_p>\n      <left_hip_roll_i>0.1</left_hip_roll_i>\n      <left_hip_roll_d>10.0</left_hip_roll_d>\n    </gains>\n  </plugin>\n</gazebo>\n'})}),"\n",(0,i.jsx)(e.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,i.jsx)(e.h3,{id:"real-time-requirements",children:"Real-time Requirements"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Control Rate"}),": 100-1000 Hz for stable control"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Computation Time"}),": Keep IK solutions under 10ms"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Communication"}),": Low-latency joint control"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"optimization-techniques",children:"Optimization Techniques"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'# Use analytical solutions when possible\ndef analytical_ik_6dof(wrist_position, wrist_orientation):\n    """\n    Analytical solution for 6-DOF manipulator\n    Much faster than numerical methods\n    """\n    # Implementation of closed-form solution\n    pass\n\n# Cache transformations\nclass CachedKinematics:\n    def __init__(self):\n        self.transform_cache = {}\n        self.last_config = None\n\n    def get_transform(self, q, link_name):\n        """\n        Get transform with caching to improve performance\n        """\n        cache_key = (tuple(np.round(q, 3)), link_name)\n\n        if cache_key != self.last_config:\n            self.transform_cache[cache_key] = self.compute_transform(q, link_name)\n            self.last_config = cache_key\n\n        return self.transform_cache[cache_key]\n'})}),"\n",(0,i.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Stability First"}),": Prioritize balance over other objectives"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Smooth Transitions"}),": Ensure smooth transitions between behaviors"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Safety Limits"}),": Respect joint limits and actuator constraints"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Modular Design"}),": Separate kinematics, dynamics, and control"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Validation"}),": Test extensively in simulation before real robot"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(e.p,{children:"After completing this module, you will be able to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Implement forward and inverse kinematics for humanoid robots"}),"\n",(0,i.jsx)(e.li,{children:"Design balance control systems using ZMP and capture point"}),"\n",(0,i.jsx)(e.li,{children:"Generate walking patterns for bipedal locomotion"}),"\n",(0,i.jsx)(e.li,{children:"Implement whole-body control with task prioritization"}),"\n",(0,i.jsx)(e.li,{children:"Integrate kinematic control with ROS 2"}),"\n",(0,i.jsx)(e.li,{children:"Handle balance recovery and push resistance"}),"\n"]})]})}function m(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>s});var o=t(6540);const i={},r=o.createContext(i);function a(n){const e=o.useContext(r);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:a(n.components),o.createElement(r.Provider,{value:e},n.children)}}}]);