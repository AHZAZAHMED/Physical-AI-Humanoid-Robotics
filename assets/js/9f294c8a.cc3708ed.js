"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[859],{8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>l});var t=i(6540);const a={},s=t.createContext(a);function o(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(s.Provider,{value:e},n.children)}},8460:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-4/cognitive-planning","title":"Cognitive Planning","description":"Cognitive planning in humanoid robotics involves creating intelligent systems that can reason about tasks, plan complex sequences of actions, and adapt to changing environments. This module explores implementing cognitive planning systems that can convert high-level goals into executable robotic behaviors using Large Language Models (LLMs).","source":"@site/docs/module-4/cognitive-planning.md","sourceDirName":"module-4","slug":"/module-4/cognitive-planning","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-4/cognitive-planning","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1765393240000,"frontMatter":{"title":"Cognitive Planning"},"sidebar":"tutorialSidebar","previous":{"title":"Voice to Action","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-4/voice-to-action"},"next":{"title":"Humanoid Kinematics and Control","permalink":"/Physical-AI-Humanoid-Robotics/docs/module-4/humanoid-kinematics-and-control"}}');var a=i(4848),s=i(8453);const o={title:"Cognitive Planning"},l="Cognitive Planning",r={},c=[{value:"Introduction to Cognitive Planning",id:"introduction-to-cognitive-planning",level:2},{value:"Architecture of Cognitive Planning Systems",id:"architecture-of-cognitive-planning-systems",level:2},{value:"Cognitive Planning Pipeline",id:"cognitive-planning-pipeline",level:3},{value:"System Components",id:"system-components",level:3},{value:"Knowledge Representation for Planning",id:"knowledge-representation-for-planning",level:2},{value:"Ontology-Based Knowledge",id:"ontology-based-knowledge",level:3},{value:"Semantic World Models",id:"semantic-world-models",level:3},{value:"Large Language Models for Planning",id:"large-language-models-for-planning",level:2},{value:"Using LLMs for Task Planning",id:"using-llms-for-task-planning",level:3},{value:"Action Validation",id:"action-validation",level:3},{value:"Hierarchical Task Networks (HTN)",id:"hierarchical-task-networks-htn",level:2},{value:"HTN Planning for Complex Tasks",id:"htn-planning-for-complex-tasks",level:3},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:2},{value:"Cognitive Planning Node",id:"cognitive-planning-node",level:3},{value:"Plan Execution and Monitoring",id:"plan-execution-and-monitoring",level:2},{value:"Execution Monitoring",id:"execution-monitoring",level:3},{value:"Learning and Adaptation",id:"learning-and-adaptation",level:2},{value:"Plan Learning from Experience",id:"plan-learning-from-experience",level:3},{value:"Cognitive Architectures",id:"cognitive-architectures",level:2},{value:"Subsumption Architecture Integration",id:"subsumption-architecture-integration",level:3},{value:"Natural Language to ROS 2 Actions",id:"natural-language-to-ros-2-actions",level:2},{value:"Converting Natural Language to ROS 2 Commands",id:"converting-natural-language-to-ros-2-commands",level:3},{value:"Performance Evaluation",id:"performance-evaluation",level:2},{value:"Metrics for Cognitive Planning",id:"metrics-for-cognitive-planning",level:3},{value:"Benchmarking Scenarios",id:"benchmarking-scenarios",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"cognitive-planning",children:"Cognitive Planning"})}),"\n",(0,a.jsx)(e.p,{children:"Cognitive planning in humanoid robotics involves creating intelligent systems that can reason about tasks, plan complex sequences of actions, and adapt to changing environments. This module explores implementing cognitive planning systems that can convert high-level goals into executable robotic behaviors using Large Language Models (LLMs)."}),"\n",(0,a.jsx)(e.h2,{id:"introduction-to-cognitive-planning",children:"Introduction to Cognitive Planning"}),"\n",(0,a.jsx)(e.p,{children:"Cognitive planning encompasses:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Task Decomposition"}),": Breaking complex goals into subtasks"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Reasoning"}),": Using knowledge to determine appropriate actions"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Planning"}),": Creating sequences of actions to achieve goals"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Adaptation"}),": Adjusting plans based on new information"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Learning"}),": Improving planning through experience"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"architecture-of-cognitive-planning-systems",children:"Architecture of Cognitive Planning Systems"}),"\n",(0,a.jsx)(e.h3,{id:"cognitive-planning-pipeline",children:"Cognitive Planning Pipeline"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Goal Understanding"}),": Interpret high-level goals"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Knowledge Retrieval"}),": Access relevant information"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Plan Generation"}),": Create action sequences"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Plan Execution"}),": Execute planned actions"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Monitoring"}),": Track execution progress"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Adaptation"}),": Modify plans based on feedback"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"system-components",children:"System Components"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Goal Parser"}),": Understands natural language goals"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Knowledge Base"}),": Stores world models and capabilities"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Planner"}),": Generates action sequences"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Executor"}),": Carries out actions"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Monitor"}),": Tracks execution state"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"knowledge-representation-for-planning",children:"Knowledge Representation for Planning"}),"\n",(0,a.jsx)(e.h3,{id:"ontology-based-knowledge",children:"Ontology-Based Knowledge"}),"\n",(0,a.jsx)(e.p,{children:"Representing knowledge about the world, objects, and actions:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"class KnowledgeBase:\n    def __init__(self):\n        self.objects = {}\n        self.locations = {}\n        self.actions = {}\n        self.capabilities = {}\n        self.rules = []\n\n    def add_object(self, obj_id, properties):\n        self.objects[obj_id] = {\n            'type': properties.get('type'),\n            'location': properties.get('location'),\n            'properties': properties.get('properties', {}),\n            'relations': properties.get('relations', {})\n        }\n\n    def add_location(self, loc_id, properties):\n        self.locations[loc_id] = properties\n\n    def add_action(self, action_id, definition):\n        self.actions[action_id] = definition\n\n    def get_related_objects(self, obj_id, relation):\n        if obj_id in self.objects:\n            obj = self.objects[obj_id]\n            if relation in obj['relations']:\n                return obj['relations'][relation]\n        return []\n"})}),"\n",(0,a.jsx)(e.h3,{id:"semantic-world-models",children:"Semantic World Models"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"class SemanticWorldModel:\n    def __init__(self):\n        self.spatial_relations = {}\n        self.functional_relations = {}\n        self.temporal_relations = {}\n\n    def add_spatial_relation(self, obj1, obj2, relation):\n        # e.g., \"cup\" is \"on\" \"table\"\n        if obj1 not in self.spatial_relations:\n            self.spatial_relations[obj1] = {}\n        self.spatial_relations[obj1][obj2] = relation\n\n    def is_reachable(self, robot_pos, target_pos):\n        # Check if target is within robot's reach\n        distance = self.calculate_distance(robot_pos, target_pos)\n        return distance <= self.robot_reach_radius\n\n    def get_path_constraints(self, start, goal):\n        # Get constraints for path planning\n        return {\n            'traversable': self.is_traversable(goal),\n            'safe': self.is_safe(goal),\n            'reachable': self.is_reachable(goal)\n        }\n"})}),"\n",(0,a.jsx)(e.h2,{id:"large-language-models-for-planning",children:"Large Language Models for Planning"}),"\n",(0,a.jsx)(e.h3,{id:"using-llms-for-task-planning",children:"Using LLMs for Task Planning"}),"\n",(0,a.jsx)(e.p,{children:"LLMs can help decompose high-level goals into executable actions:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'import openai\nimport json\n\nclass LLMPlanner:\n    def __init__(self, api_key):\n        openai.api_key = api_key\n        self.client = openai.OpenAI()\n\n    def generate_plan(self, goal, context, available_actions):\n        prompt = f"""\n        You are a robot task planner. Given the goal, current context, and available actions,\n        create a step-by-step plan to achieve the goal.\n\n        Goal: {goal}\n        Context: {context}\n        Available Actions: {available_actions}\n\n        Respond with a JSON object containing:\n        - "plan": list of action objects with "action", "parameters", and "reasoning"\n        - "estimated_steps": number of steps required\n        - "potential_issues": list of potential issues\n\n        Ensure each action is executable by the robot and consider the physical constraints.\n        """\n\n        response = self.client.chat.completions.create(\n            model="gpt-4",\n            messages=[{"role": "user", "content": prompt}],\n            temperature=0.3\n        )\n\n        try:\n            plan_data = json.loads(response.choices[0].message.content)\n            return plan_data\n        except json.JSONDecodeError:\n            # Handle case where response isn\'t valid JSON\n            return self.parse_plan_from_text(response.choices[0].message.content)\n'})}),"\n",(0,a.jsx)(e.h3,{id:"action-validation",children:"Action Validation"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"class PlanValidator:\n    def __init__(self, knowledge_base):\n        self.kb = knowledge_base\n\n    def validate_plan(self, plan):\n        for step in plan['plan']:\n            action = step['action']\n            params = step['parameters']\n\n            # Check if action is available\n            if action not in self.kb.actions:\n                return False, f\"Action '{action}' is not available\"\n\n            # Check preconditions\n            preconditions = self.kb.actions[action].get('preconditions', [])\n            for precondition in preconditions:\n                if not self.check_precondition(precondition, params):\n                    return False, f\"Precondition failed: {precondition}\"\n\n            # Check physical feasibility\n            if not self.check_physical_feasibility(action, params):\n                return False, f\"Action not physically feasible: {action}\"\n\n        return True, \"Plan is valid\"\n\n    def check_precondition(self, precondition, params):\n        # Implement precondition checking logic\n        # This would check if conditions are met before action execution\n        pass\n\n    def check_physical_feasibility(self, action, params):\n        # Check if action is physically possible\n        # Consider robot kinematics, workspace, etc.\n        pass\n"})}),"\n",(0,a.jsx)(e.h2,{id:"hierarchical-task-networks-htn",children:"Hierarchical Task Networks (HTN)"}),"\n",(0,a.jsx)(e.h3,{id:"htn-planning-for-complex-tasks",children:"HTN Planning for Complex Tasks"}),"\n",(0,a.jsx)(e.p,{children:"Breaking down complex tasks into manageable subtasks:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'class HTNPlanner:\n    def __init__(self):\n        self.tasks = {}\n        self.methods = {}\n\n    def add_task(self, task_name, description):\n        self.tasks[task_name] = description\n\n    def add_method(self, task, method_name, decomposition):\n        """\n        Add a method to decompose a task\n        decomposition: list of subtasks to achieve the main task\n        """\n        if task not in self.methods:\n            self.methods[task] = []\n        self.methods[task].append({\n            \'name\': method_name,\n            \'decomposition\': decomposition\n        })\n\n    def decompose_task(self, task, context):\n        """\n        Decompose a high-level task into subtasks\n        """\n        if task not in self.methods:\n            # Primitive task - no further decomposition needed\n            return [task]\n\n        # Try each method for the task\n        for method in self.methods[task]:\n            if self.is_applicable(method, context):\n                subtasks = []\n                for subtask in method[\'decomposition\']:\n                    subtasks.extend(self.decompose_task(subtask, context))\n                return subtasks\n\n        return []  # No applicable method found\n\n    def is_applicable(self, method, context):\n        # Check if method is applicable given current context\n        # This would check preconditions, available resources, etc.\n        return True\n'})}),"\n",(0,a.jsx)(e.h2,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,a.jsx)(e.h3,{id:"cognitive-planning-node",children:"Cognitive Planning Node"}),"\n",(0,a.jsx)(e.p,{children:"Creating a ROS 2 node for cognitive planning:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom std_msgs.msg import String\nfrom geometry_msgs.msg import Pose\nfrom action_msgs.msg import GoalStatus\n\nclass CognitivePlannerNode(Node):\n    def __init__(self):\n        super().__init__('cognitive_planner_node')\n\n        # Publishers and subscribers\n        self.plan_pub = self.create_publisher(String, 'execution_plan', 10)\n        self.status_pub = self.create_publisher(String, 'planning_status', 10)\n        self.goal_sub = self.create_subscription(\n            String, 'high_level_goal', self.goal_callback, 10)\n\n        # Initialize planners\n        self.llm_planner = LLMPlanner(api_key=self.get_parameter('openai_api_key').value)\n        self.knowledge_base = KnowledgeBase()\n        self.validator = PlanValidator(self.knowledge_base)\n\n        self.get_logger().info('Cognitive Planner Node initialized')\n\n    def goal_callback(self, msg):\n        goal = msg.data\n        self.get_logger().info(f'Received high-level goal: {goal}')\n\n        # Get current context\n        context = self.get_current_context()\n\n        # Generate plan using LLM\n        plan = self.llm_planner.generate_plan(\n            goal=goal,\n            context=context,\n            available_actions=self.get_available_actions()\n        )\n\n        # Validate plan\n        is_valid, reason = self.validator.validate_plan(plan)\n        if is_valid:\n            # Execute plan\n            self.execute_plan(plan)\n        else:\n            self.get_logger().error(f'Invalid plan: {reason}')\n            self.publish_status(f'Planning failed: {reason}')\n\n    def get_current_context(self):\n        # Gather current state information\n        context = {\n            'robot_pose': self.get_robot_pose(),\n            'detected_objects': self.get_detected_objects(),\n            'available_tools': self.get_available_tools(),\n            'environment_map': self.get_environment_map()\n        }\n        return context\n\n    def execute_plan(self, plan):\n        # Publish plan for execution\n        plan_msg = String()\n        plan_msg.data = json.dumps(plan)\n        self.plan_pub.publish(plan_msg)\n\n        # Monitor execution\n        self.monitor_execution(plan)\n"})}),"\n",(0,a.jsx)(e.h2,{id:"plan-execution-and-monitoring",children:"Plan Execution and Monitoring"}),"\n",(0,a.jsx)(e.h3,{id:"execution-monitoring",children:"Execution Monitoring"}),"\n",(0,a.jsx)(e.p,{children:"Tracking plan execution and handling failures:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"class PlanExecutionMonitor:\n    def __init__(self, robot_interface):\n        self.robot_interface = robot_interface\n        self.current_plan = None\n        self.current_step = 0\n        self.execution_history = []\n\n    def execute_plan(self, plan):\n        self.current_plan = plan\n        self.current_step = 0\n\n        for i, step in enumerate(plan['plan']):\n            self.current_step = i\n            success = self.execute_step(step)\n\n            if not success:\n                # Handle failure\n                recovery_plan = self.generate_recovery_plan(step, plan)\n                if recovery_plan:\n                    self.execute_plan(recovery_plan)\n                else:\n                    # Plan failed completely\n                    return False\n\n        return True\n\n    def execute_step(self, step):\n        action = step['action']\n        params = step['parameters']\n\n        try:\n            # Execute the action\n            result = self.robot_interface.execute_action(action, params)\n\n            # Log execution\n            self.execution_history.append({\n                'step': step,\n                'result': result,\n                'timestamp': time.time()\n            })\n\n            return result['success']\n        except Exception as e:\n            self.get_logger().error(f'Error executing step: {e}')\n            return False\n\n    def generate_recovery_plan(self, failed_step, original_plan):\n        # Generate a plan to recover from failure\n        # This could involve:\n        # - Replanning around the failure\n        # - Using alternative actions\n        # - Requesting human assistance\n        pass\n"})}),"\n",(0,a.jsx)(e.h2,{id:"learning-and-adaptation",children:"Learning and Adaptation"}),"\n",(0,a.jsx)(e.h3,{id:"plan-learning-from-experience",children:"Plan Learning from Experience"}),"\n",(0,a.jsx)(e.p,{children:"Improving planning through experience:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"class PlanLearner:\n    def __init__(self):\n        self.execution_records = []\n        self.success_patterns = {}\n        self.failure_patterns = {}\n\n    def record_execution(self, plan, context, outcome, execution_trace):\n        record = {\n            'plan': plan,\n            'context': context,\n            'outcome': outcome,\n            'trace': execution_trace,\n            'timestamp': time.time()\n        }\n        self.execution_records.append(record)\n\n        # Update patterns based on outcome\n        if outcome['success']:\n            self.update_success_patterns(plan, context)\n        else:\n            self.update_failure_patterns(plan, context, outcome['reason'])\n\n    def update_success_patterns(self, plan, context):\n        # Learn patterns that lead to success\n        for step in plan['plan']:\n            action = step['action']\n            if action not in self.success_patterns:\n                self.success_patterns[action] = []\n            self.success_patterns[action].append(context)\n\n    def update_failure_patterns(self, plan, context, reason):\n        # Learn patterns that lead to failure\n        for step in plan['plan']:\n            action = step['action']\n            if action not in self.failure_patterns:\n                self.failure_patterns[action] = {}\n            if reason not in self.failure_patterns[action]:\n                self.failure_patterns[action][reason] = []\n            self.failure_patterns[action][reason].append(context)\n\n    def suggest_improved_plan(self, goal, context):\n        # Use learned patterns to suggest better plans\n        # This could involve avoiding actions that commonly fail\n        # in similar contexts or preferring actions that commonly succeed\n        pass\n"})}),"\n",(0,a.jsx)(e.h2,{id:"cognitive-architectures",children:"Cognitive Architectures"}),"\n",(0,a.jsx)(e.h3,{id:"subsumption-architecture-integration",children:"Subsumption Architecture Integration"}),"\n",(0,a.jsx)(e.p,{children:"Combining high-level planning with reactive behaviors:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"class CognitiveArchitecture:\n    def __init__(self):\n        self.high_level_planner = LLMPlanner()\n        self.reactive_layer = ReactiveBehaviorLayer()\n        self.arbitrator = PlanArbitrator()\n\n    def process_command(self, goal, context):\n        # Generate high-level plan\n        high_level_plan = self.high_level_planner.generate_plan(goal, context)\n\n        # Generate reactive behaviors for immediate needs\n        reactive_behaviors = self.reactive_layer.get_behaviors(context)\n\n        # Arbitrate between planned and reactive actions\n        action = self.arbitrator.select_action(high_level_plan, reactive_behaviors, context)\n\n        return action\n\nclass PlanArbitrator:\n    def __init__(self):\n        self.priority_rules = [\n            # Safety > Goal achievement > Efficiency\n            self.check_safety_constraints,\n            self.check_immediate_danger,\n            self.check_opportunity,\n            self.follow_plan\n        ]\n\n    def select_action(self, plan, behaviors, context):\n        for rule in self.priority_rules:\n            action = rule(plan, behaviors, context)\n            if action is not None:\n                return action\n        return None\n"})}),"\n",(0,a.jsx)(e.h2,{id:"natural-language-to-ros-2-actions",children:"Natural Language to ROS 2 Actions"}),"\n",(0,a.jsx)(e.h3,{id:"converting-natural-language-to-ros-2-commands",children:"Converting Natural Language to ROS 2 Commands"}),"\n",(0,a.jsx)(e.p,{children:"Mapping high-level language to specific ROS 2 actions:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"class NaturalLanguageMapper:\n    def __init__(self):\n        self.action_templates = {\n            'navigation': {\n                'keywords': ['go to', 'move to', 'navigate to', 'walk to', 'travel to'],\n                'template': self.create_navigation_goal,\n                'topic': '/navigate_to_pose'\n            },\n            'manipulation': {\n                'keywords': ['pick up', 'grasp', 'take', 'get', 'place', 'put'],\n                'template': self.create_manipulation_command,\n                'topic': '/manipulation/command'\n            },\n            'interaction': {\n                'keywords': ['talk to', 'greet', 'introduce', 'communicate'],\n                'template': self.create_interaction_command,\n                'topic': '/interaction/command'\n            }\n        }\n\n    def map_language_to_action(self, text_command):\n        for action_type, config in self.action_templates.items():\n            for keyword in config['keywords']:\n                if keyword in text_command.lower():\n                    # Extract parameters and create ROS message\n                    ros_msg = config['template'](text_command)\n                    return {\n                        'topic': config['topic'],\n                        'message': ros_msg,\n                        'action_type': action_type\n                    }\n\n        return None\n\n    def create_navigation_goal(self, command):\n        # Extract location from command\n        location = self.extract_location(command)\n        pose = self.get_pose_for_location(location)\n\n        from geometry_msgs.msg import PoseStamped\n        goal = PoseStamped()\n        goal.pose = pose\n        return goal\n\n    def extract_location(self, command):\n        # Use NLP to extract location entities\n        # This would involve named entity recognition\n        pass\n"})}),"\n",(0,a.jsx)(e.h2,{id:"performance-evaluation",children:"Performance Evaluation"}),"\n",(0,a.jsx)(e.h3,{id:"metrics-for-cognitive-planning",children:"Metrics for Cognitive Planning"}),"\n",(0,a.jsx)(e.p,{children:"Evaluating the effectiveness of cognitive planning systems:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Plan Success Rate"}),": Percentage of plans that achieve goals"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Plan Efficiency"}),": Steps taken vs. optimal steps"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Adaptability"}),": Ability to handle unexpected situations"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Response Time"}),": Time to generate and execute plans"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Resource Usage"}),": Computational and energy requirements"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"benchmarking-scenarios",children:"Benchmarking Scenarios"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Simple Tasks"}),": Basic navigation and manipulation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Complex Tasks"}),": Multi-step tasks with dependencies"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Dynamic Environments"}),": Changing conditions"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Failure Recovery"}),": Handling plan failures"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Validation"}),": Always validate plans before execution"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Safety"}),": Prioritize safety in plan generation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Modularity"}),": Design modular planning components"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Monitoring"}),": Continuously monitor plan execution"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Learning"}),": Incorporate learning from experience"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,a.jsx)(e.p,{children:"After completing this module, you will be able to:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Design cognitive planning systems for humanoid robots"}),"\n",(0,a.jsx)(e.li,{children:"Implement knowledge representation for planning"}),"\n",(0,a.jsx)(e.li,{children:"Integrate LLMs for task decomposition"}),"\n",(0,a.jsx)(e.li,{children:"Create hierarchical task networks"}),"\n",(0,a.jsx)(e.li,{children:"Monitor and adapt plan execution"}),"\n",(0,a.jsx)(e.li,{children:"Convert natural language to robotic actions"}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}}}]);