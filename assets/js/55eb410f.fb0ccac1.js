"use strict";(globalThis.webpackChunkphysical_ai_textbook=globalThis.webpackChunkphysical_ai_textbook||[]).push([[575],{9881:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Introduction & Foundations","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/docs/intro","label":"Introduction to Physical AI & Humanoid Robotics","docId":"intro","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/foundations-of-physical-ai","label":"Foundations of Physical AI","docId":"foundations-of-physical-ai","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/humanoid-robotics-overview","label":"Humanoid Robotics Overview","docId":"humanoid-robotics-overview","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 1: ROS 2 Fundamentals","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-1/ros-2-architecture","label":"ROS 2 Architecture","docId":"module-1/ros-2-architecture","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-1/nodes-topics-and-services","label":"Nodes, Topics, and Services","docId":"module-1/nodes-topics-and-services","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-1/urdf-and-packages","label":"URDF and Packages","docId":"module-1/urdf-and-packages","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: Simulation","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-2/gazebo-setup-and-physics","label":"Gazebo Setup and Physics","docId":"module-2/gazebo-setup-and-physics","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-2/unity-and-high-fidelity-rendering","label":"Unity and High-Fidelity Rendering","docId":"module-2/unity-and-high-fidelity-rendering","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-2/sensor-simulation","label":"Sensor Simulation","docId":"module-2/sensor-simulation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: NVIDIA Isaac Platform","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-3/isaac-sim-and-sdk","label":"Isaac Sim and SDK","docId":"module-3/isaac-sim-and-sdk","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-3/isaac-ros-and-vslam","label":"Isaac ROS and VSLAM","docId":"module-3/isaac-ros-and-vslam","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-3/nav2-and-bipedal-movement","label":"Nav2 and Bipedal Movement","docId":"module-3/nav2-and-bipedal-movement","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: VLA & Humanoid Development","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-4/voice-to-action","label":"Voice to Action","docId":"module-4/voice-to-action","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-4/cognitive-planning","label":"Cognitive Planning","docId":"module-4/cognitive-planning","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/module-4/humanoid-kinematics-and-control","label":"Humanoid Kinematics and Control","docId":"module-4/humanoid-kinematics-and-control","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Assessments & Hardware","items":[{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/assessments/hardware-requirements","label":"Hardware Requirements","docId":"assessments/hardware-requirements","unlisted":false},{"type":"link","href":"/Physical-AI-Humanoid-Robotics/docs/assessments/capstone-project-definition","label":"Capstone Project Definition","docId":"assessments/capstone-project-definition","unlisted":false}],"collapsed":true,"collapsible":true}]},"docs":{"assessments/capstone-project-definition":{"id":"assessments/capstone-project-definition","title":"Capstone Project Definition","description":"The capstone project integrates all concepts learned throughout the Physical AI & Humanoid Robotics course. Students will implement a complete humanoid robot system capable of understanding natural language commands, navigating environments, manipulating objects, and maintaining balance.","sidebar":"tutorialSidebar"},"assessments/hardware-requirements":{"id":"assessments/hardware-requirements","title":"Hardware Requirements","description":"This module outlines the hardware specifications needed for developing and deploying humanoid robotics systems, including both the \\"Digital Twin\\" workstation and the \\"Physical AI\\" Edge Kit.","sidebar":"tutorialSidebar"},"foundations-of-physical-ai":{"id":"foundations-of-physical-ai","title":"Foundations of Physical AI","description":"Physical AI represents a paradigm shift from traditional AI systems that operate purely in digital spaces to AI systems that interact with and understand the physical world. This module introduces the core concepts that differentiate Physical AI from conventional AI approaches.","sidebar":"tutorialSidebar"},"humanoid-robotics-overview":{"id":"humanoid-robotics-overview","title":"Humanoid Robotics Overview","description":"Humanoid robots are designed to mimic human form and behavior, offering unique advantages in human environments. This module provides an overview of humanoid robotics, including design principles, challenges, and applications.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction to Physical AI & Humanoid Robotics","description":"Welcome to the comprehensive textbook on Physical AI and Humanoid Robotics. This course is designed to provide you with a deep understanding of embodied intelligence, bridging the gap between digital AI systems and physical robotic platforms.","sidebar":"tutorialSidebar"},"module-1/nodes-topics-and-services":{"id":"module-1/nodes-topics-and-services","title":"Nodes, Topics, and Services","description":"Understanding the fundamental communication patterns in ROS 2 is essential for developing distributed robotic systems. This module covers the three primary communication mechanisms: nodes, topics, and services.","sidebar":"tutorialSidebar"},"module-1/ros-2-architecture":{"id":"module-1/ros-2-architecture","title":"ROS 2 Architecture","description":"The Robot Operating System 2 (ROS 2) provides the foundational communication framework for modern robotics applications. This module introduces the core architectural concepts of ROS 2 and how they enable distributed robotic systems.","sidebar":"tutorialSidebar"},"module-1/urdf-and-packages":{"id":"module-1/urdf-and-packages","title":"URDF and Packages","description":"Unified Robot Description Format (URDF) and ROS packages form the foundation for describing robots and organizing code in ROS 2. This module covers how to create robot descriptions and organize your code into reusable packages.","sidebar":"tutorialSidebar"},"module-2/gazebo-setup-and-physics":{"id":"module-2/gazebo-setup-and-physics","title":"Gazebo Setup and Physics","description":"Gazebo is a powerful 3D simulation environment that provides realistic physics simulation for robotics development. This module covers setting up Gazebo and understanding its physics engine for humanoid robotics applications.","sidebar":"tutorialSidebar"},"module-2/sensor-simulation":{"id":"module-2/sensor-simulation","title":"Sensor Simulation","description":"Sensor simulation is critical for robotics development, allowing for testing and training without physical hardware. This module covers simulating various sensors used in humanoid robotics, including LiDAR, cameras, IMUs, and force/torque sensors.","sidebar":"tutorialSidebar"},"module-2/unity-and-high-fidelity-rendering":{"id":"module-2/unity-and-high-fidelity-rendering","title":"Unity and High-Fidelity Rendering","description":"While Gazebo provides excellent physics simulation, Unity offers high-fidelity rendering capabilities that are essential for advanced robotics applications, particularly in computer vision and perception tasks. This module explores using Unity for robotics simulation.","sidebar":"tutorialSidebar"},"module-3/isaac-ros-and-vslam":{"id":"module-3/isaac-ros-and-vslam","title":"Isaac ROS and VSLAM","description":"Isaac ROS is a collection of hardware-accelerated perception and navigation packages that enable robots to perceive and navigate in complex environments. This module focuses on Visual Simultaneous Localization and Mapping (VSLAM) using Isaac ROS packages.","sidebar":"tutorialSidebar"},"module-3/isaac-sim-and-sdk":{"id":"module-3/isaac-sim-and-sdk","title":"Isaac Sim and SDK","description":"NVIDIA Isaac Sim is a powerful robotics simulation platform built on NVIDIA Omniverse, designed for developing and testing AI-based robotics applications. This module covers Isaac Sim and the Isaac SDK for robotics development.","sidebar":"tutorialSidebar"},"module-3/nav2-and-bipedal-movement":{"id":"module-3/nav2-and-bipedal-movement","title":"Nav2 and Bipedal Movement","description":"Navigation 2 (Nav2) is the navigation stack for ROS 2, providing path planning, obstacle avoidance, and navigation capabilities. This module covers implementing navigation for bipedal humanoid robots, addressing the unique challenges of legged locomotion.","sidebar":"tutorialSidebar"},"module-4/cognitive-planning":{"id":"module-4/cognitive-planning","title":"Cognitive Planning","description":"Cognitive planning in humanoid robotics involves creating intelligent systems that can reason about tasks, plan complex sequences of actions, and adapt to changing environments. This module explores implementing cognitive planning systems that can convert high-level goals into executable robotic behaviors using Large Language Models (LLMs).","sidebar":"tutorialSidebar"},"module-4/humanoid-kinematics-and-control":{"id":"module-4/humanoid-kinematics-and-control","title":"Humanoid Kinematics and Control","description":"Humanoid kinematics and control form the foundation for enabling human-like movement and interaction in robotic systems. This module covers the mathematical foundations, control strategies, and implementation techniques for humanoid robot motion.","sidebar":"tutorialSidebar"},"module-4/voice-to-action":{"id":"module-4/voice-to-action","title":"Voice to Action","description":"Voice to Action (VTA) systems enable humanoid robots to understand spoken commands and convert them into executable robotic actions. This module covers implementing voice recognition, natural language processing, and action execution for humanoid robots.","sidebar":"tutorialSidebar"}}}}')}}]);